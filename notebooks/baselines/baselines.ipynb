{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('NLP-seminar-env': conda)","metadata":{"interpreter":{"hash":"a192f6a2a07440443dd9813f45d39f6276bab8996f4682d1023cc32088b348cc"}}},"colab":{"name":"baselines.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTf04r6kTFAQ","executionInfo":{"status":"ok","timestamp":1606742504789,"user_tz":-60,"elapsed":2268,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"0d2a66a0-90bf-401a-84db-fbf05dbad6e5"},"source":["#Mount Drive if running in Colab\n","from sys import path\n","import os\n","\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","\n","  root_PATH = '/content/drive/My Drive/nlp-seminar/repository'\n","  drive_mount_location = '/content/drive'\n","\n","  drive.mount(drive_mount_location, force_remount=True)\n","  path.append(root_PATH)\n","else:\n","  root_PATH = os.path.abspath(\"../..\")\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","module_path = os.path.abspath(os.path.join('../../src'))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)"],"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"p_pvZ4IrStrd","executionInfo":{"status":"ok","timestamp":1606742537475,"user_tz":-60,"elapsed":6479,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"3657d8b3-c88e-4bfe-c166-533a7861bf4c"},"source":["import pandas as pd\n","from data_cleaner import DataCleaner\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","from sklearn.multiclass import OneVsRestClassifier\n","from nltk.corpus import stopwords\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","\n","train_df = pd.read_csv(root_PATH + '/data/train.csv')\n","validation_df = pd.read_csv(root_PATH + '/data/validation.csv')"],"execution_count":78,"outputs":[]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["#Load and clean the datasets\n","train_df = train_df.head(1000)\n","validation_df = validation_df.head(1000)\n","\n","train_df['Conversation'] = train_df['Conversation'].map(lambda com : DataCleaner.clean_text_naive_bayes(str(com)))\n","validation_df['Conversation'] = validation_df['Conversation'].map(lambda com : DataCleaner.clean_text_naive_bayes(str(com)))"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["#Obtain a list with all the topics in the dataset\n","train_df[\"Topic\"] = train_df[\"Topic\"].apply(eval)\n","\n","def list_to_series(series):\n","    return pd.Series([x for _list in series for x in _list])\n","\n","topics_list = list_to_series(train_df[\"Topic\"]).unique()"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nx_train = train_df.Conversation\\ny_train = train_df.Topic\\n\\nx_test = validation_df.Conversation\\ny_test = \\n\\nstop_words = set(stopwords.words('english'))\\n\\nNB_pipeline = Pipeline([\\n                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\\n                ('clf', OneVsRestClassifier(MultinomialNB(\\n                    fit_prior=True, class_prior=None))),\\n            ])\\n\\naccuracy_score\\n\\nfor topic in topics_list:\\n    print('... Processing {}'.format(topic))\\n    # train the model using X_dtm & y\\n    #NB_pipeline.fit(x_train, train_df[topic])\\n    # compute the testing accuracy\\n    #prediction = NB_pipeline.predict(X_test)\\n    #print('Test accuracy is {}'.format(accuracy_score(validation_df[topic], prediction)))\\n\""]},"metadata":{},"execution_count":93}],"source":["#Run Naive Bayes Classifier\n","'''\n","x_train = train_df.Conversation\n","y_train = train_df.Topic\n","\n","x_test = validation_df.Conversation\n","y_test = \n","\n","stop_words = set(stopwords.words('english'))\n","\n","NB_pipeline = Pipeline([\n","                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n","                ('clf', OneVsRestClassifier(MultinomialNB(\n","                    fit_prior=True, class_prior=None))),\n","            ])\n","\n","accuracy_score\n","\n","for topic in topics_list:\n","    print('... Processing {}'.format(topic))\n","    # train the model using X_dtm & y\n","    #NB_pipeline.fit(x_train, train_df[topic])\n","    # compute the testing accuracy\n","    #prediction = NB_pipeline.predict(X_test)\n","    #print('Test accuracy is {}'.format(accuracy_score(validation_df[topic], prediction)))\n","'''"]}]}