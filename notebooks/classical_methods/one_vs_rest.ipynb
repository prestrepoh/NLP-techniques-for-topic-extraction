{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('NLP-seminar-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a192f6a2a07440443dd9813f45d39f6276bab8996f4682d1023cc32088b348cc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount Drive if running in Colab\n",
    "from sys import path\n",
    "import os\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "\n",
    "  root_PATH = '/content/drive/My Drive/nlp-seminar/repository'\n",
    "  drive_mount_location = '/content/drive'\n",
    "\n",
    "  drive.mount(drive_mount_location, force_remount=True)\n",
    "  path.append(root_PATH)\n",
    "else:\n",
    "  root_PATH = os.path.abspath(\"../..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaner import DataCleaner\n",
    "from data_processor import DataProcessor\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration variables\n",
    "#remove under-represented categories below this threshold\n",
    "underrepresented_threshold = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "train_df = pd.read_csv(root_PATH + '/data/train.csv')\n",
    "validation_df = pd.read_csv(root_PATH + '/data/validation.csv')\n",
    "\n",
    "#Convert topics column to list\n",
    "train_df[\"Topic\"] = train_df[\"Topic\"].apply(eval)\n",
    "validation_df[\"Topic\"] = validation_df[\"Topic\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean datasets for classical methods\n",
    "train_df['Conversation'] = train_df['Conversation'].map(lambda row : DataCleaner.clean_text_for_classical_methods(str(row)))\n",
    "validation_df['Conversation'] = validation_df['Conversation'].map(lambda row : DataCleaner.clean_text_for_classical_methods(str(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate boolean masks for our datasets\n",
    "train_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(train_df)\n",
    "validation_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(validation_df)\n",
    "\n",
    "#Remove underrepresented topics\n",
    "underrepresented_topics = DataProcessor.get_underrepresented_topics(train_df,underrepresented_threshold)\n",
    "\n",
    "train_df, remaining_topics = DataProcessor.remove_topics_from_dataset(train_df,train_boolean_mask,underrepresented_topics)\n",
    "validation_df, _ = DataProcessor.remove_topics_from_dataset(validation_df,validation_boolean_mask,underrepresented_topics)\n",
    "\n",
    "#Generate boolean masks for our new dataset\n",
    "train_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(train_df)\n",
    "validation_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(validation_df)"
   ]
  },
  {
   "source": [
    "## One Vs Rest Classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... Processing Satisfied users\n",
      "Test accuracy is 0.8403588585244807\n",
      "... Processing Bugs\n",
      "Test accuracy is 0.9192504692520599\n",
      "... Processing Design & UX\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d5081ad202c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'... Processing {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# train the model using X_dtm & y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mNB_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_boolean_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# compute the testing accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNB_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP-seminar-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP-seminar-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP-seminar-env\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP-seminar-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP-seminar-env\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \"\"\"\n\u001b[0;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train and evaluate a Multinonial Naive Bayes classifier (without stemming)\n",
    "x_train = train_df[\"Conversation\"]\n",
    "x_test = validation_df[\"Conversation\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "for topic in remaining_topics:\n",
    "    print('... Processing {}'.format(topic))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(x_train, train_boolean_mask[topic])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(x_test)\n",
    "    \n",
    "    print('Test accuracy is {}'.format(accuracy_score(validation_boolean_mask[topic], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... Processing Satisfied users\n",
      "Test accuracy is 0.8671337563419503\n",
      "... Processing Bugs\n",
      "Test accuracy is 0.9654705441043704\n",
      "... Processing Design & UX\n",
      "Test accuracy is 0.9716567272357362\n",
      "... Processing Dissatisfied users\n",
      "Test accuracy is 0.9556540315094796\n",
      "... Processing Performance\n",
      "Test accuracy is 0.987544981752985\n",
      "... Processing Use cases\n",
      "Test accuracy is 0.9615922586879951\n",
      "... Processing Gaming\n",
      "Test accuracy is 0.9826748725252089\n",
      "... Processing Feature Requests\n",
      "Test accuracy is 0.9691962412420686\n",
      "... Processing Complexity\n",
      "Test accuracy is 0.9897193647241331\n",
      "... Processing Pricing\n",
      "Test accuracy is 0.9901326246455502\n",
      "... Processing Security & Accounts\n",
      "Test accuracy is 0.9936866599697367\n",
      "... Processing Update\n",
      "Test accuracy is 0.9881553348676932\n",
      "... Processing Camera & Photos\n",
      "Test accuracy is 0.9966875627837188\n",
      "... Processing Video\n",
      "Test accuracy is 0.9980608572918124\n",
      "... Processing Customer Support\n",
      "Test accuracy is 0.9919509682997851\n",
      "... Processing Notifications & Alerts\n",
      "Test accuracy is 0.9982897397098279\n",
      "... Processing Frequency\n",
      "Test accuracy is 0.9881934819373626\n",
      "... Processing Advertising\n",
      "Test accuracy is 0.9976030924557812\n",
      "... Processing Payment\n",
      "Test accuracy is 0.9961407881184594\n",
      "... Processing Connectivity\n",
      "Test accuracy is 0.9959119057004437\n",
      "... Processing Devices\n",
      "Test accuracy is 0.9959818419948374\n",
      "... Processing Audio\n",
      "Test accuracy is 0.9980926465165367\n",
      "... Processing Sign Up & Login\n",
      "Test accuracy is 0.9937184491944611\n",
      "... Processing Location Services\n",
      "Test accuracy is 0.9992752056762839\n",
      "... Processing Privacy\n",
      "Test accuracy is 0.9982198034154343\n",
      "... Processing Internationalization\n",
      "Test accuracy is 0.9991544066223313\n",
      "... Processing Streaming\n",
      "Test accuracy is 0.9993069949010084\n",
      "... Processing Social & Collaboration\n",
      "Test accuracy is 0.9991226173976069\n",
      "... Processing Import Export\n",
      "Test accuracy is 0.9997329705123151\n",
      "... Processing Battery\n",
      "Test accuracy is 0.9995485930089137\n",
      "... Processing Operating System\n",
      "Test accuracy is 0.9998728431011025\n",
      "... Processing Touch ID\n",
      "Test accuracy is 0.9999109901707717\n",
      "... Processing HDMI\n",
      "Test accuracy is 0.9999364215505512\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate an SV classifier (without stemming)\n",
    "\n",
    "x_train = train_df[\"Conversation\"]\n",
    "x_test = validation_df[\"Conversation\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "for topic in remaining_topics:\n",
    "    print('... Processing {}'.format(topic))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(x_train, train_boolean_mask[topic])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(x_test)\n",
    "    \n",
    "    print('Test accuracy is {}'.format(accuracy_score(validation_boolean_mask[topic], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... Processing Satisfied users\n",
      "Test accuracy is 0.8708213064099792\n",
      "... Processing Bugs\n",
      "Test accuracy is 0.9648411174548275\n",
      "... Processing Design & UX\n",
      "Test accuracy is 0.9699973297051232\n",
      "... Processing Dissatisfied users\n",
      "Test accuracy is 0.9562898160039673\n",
      "... Processing Performance\n",
      "Test accuracy is 0.9859110156021514\n",
      "... Processing Use cases\n",
      "Test accuracy is 0.9613760919598693\n",
      "... Processing Gaming\n",
      "Test accuracy is 0.9814732398306271\n",
      "... Processing Feature Requests\n",
      "Test accuracy is 0.9687893391655964\n",
      "... Processing Complexity\n",
      "Test accuracy is 0.990037256971377\n",
      "... Processing Pricing\n",
      "Test accuracy is 0.9887529722925117\n",
      "... Processing Security & Accounts\n",
      "Test accuracy is 0.9917030123469349\n",
      "... Processing Update\n",
      "Test accuracy is 0.9864959373370802\n",
      "... Processing Camera & Photos\n",
      "Test accuracy is 0.9955812977633102\n",
      "... Processing Video\n",
      "Test accuracy is 0.9973487786579861\n",
      "... Processing Customer Support\n",
      "Test accuracy is 0.9915758554480373\n",
      "... Processing Notifications & Alerts\n",
      "Test accuracy is 0.9972661266737027\n",
      "... Processing Frequency\n",
      "Test accuracy is 0.987646707272103\n",
      "... Processing Advertising\n",
      "Test accuracy is 0.99662398433427\n",
      "... Processing Payment\n",
      "Test accuracy is 0.9952506898261765\n",
      "... Processing Connectivity\n",
      "Test accuracy is 0.9949137240440981\n",
      "... Processing Devices\n",
      "Test accuracy is 0.9951044593924443\n",
      "... Processing Audio\n",
      "Test accuracy is 0.9968910138219549\n",
      "... Processing Sign Up & Login\n",
      "Test accuracy is 0.993514998156225\n",
      "... Processing Location Services\n",
      "Test accuracy is 0.9984550436783948\n",
      "... Processing Privacy\n",
      "Test accuracy is 0.9974695777119388\n",
      "... Processing Internationalization\n",
      "Test accuracy is 0.9982134455704894\n",
      "... Processing Streaming\n",
      "Test accuracy is 0.9987920094604733\n",
      "... Processing Social & Collaboration\n",
      "Test accuracy is 0.9989000928245362\n",
      "... Processing Import Export\n",
      "Test accuracy is 0.9994150782650713\n",
      "... Processing Battery\n",
      "Test accuracy is 0.9994977302493547\n",
      "... Processing Operating System\n",
      "Test accuracy is 0.9998728431011025\n",
      "... Processing Touch ID\n",
      "Test accuracy is 0.999898274480882\n",
      "... Processing HDMI\n",
      "Test accuracy is 0.9999173480157166\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate a Logistic Regression classifier (without stemming)\n",
    "\n",
    "x_train = train_df[\"Conversation\"]\n",
    "x_test = validation_df[\"Conversation\"]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "for topic in remaining_topics:\n",
    "    print('... Processing {}'.format(topic))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(x_train, train_boolean_mask[topic])\n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(validation_boolean_mask[topic], prediction)))"
   ]
  }
 ]
}