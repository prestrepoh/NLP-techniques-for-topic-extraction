{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('NLP-seminar-env': conda)","metadata":{"interpreter":{"hash":"a192f6a2a07440443dd9813f45d39f6276bab8996f4682d1023cc32088b348cc"}}},"colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4226a375a5834773bf922fb5a8097866":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2b4ba0e511d0449eb16522f06105bbba","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c8c58a7f977947578c9a1c74c7a4004a","IPY_MODEL_a495d83fdba446ca9a1967a8d3f2120f"]}},"2b4ba0e511d0449eb16522f06105bbba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8c58a7f977947578c9a1c74c7a4004a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34006378d81941a79325e4b98614ab1c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f236e56b821e4820bf95917babe5bf26"}},"a495d83fdba446ca9a1967a8d3f2120f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e6be3f61aa74ecebc6204eb5e6c79cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 2.83MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65a06a01075c4c17bcb1a20a7b56d10a"}},"34006378d81941a79325e4b98614ab1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f236e56b821e4820bf95917babe5bf26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e6be3f61aa74ecebc6204eb5e6c79cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"65a06a01075c4c17bcb1a20a7b56d10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"s_ANk63bF5X-"},"source":["# Fine-Tunning a BERT model for topic classification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfDaswRdF5YE","executionInfo":{"status":"ok","timestamp":1609154645751,"user_tz":-60,"elapsed":20477,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"a83f32dd-6846-49db-8f32-287c99def431"},"source":["def install_dependecies():\n","  !pip install transformers\n","\n","#Mount Drive if running in Colab\n","from sys import path\n","import os\n","import sys\n","\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","\n","  root_PATH = '/content/drive/My Drive/nlp-seminar/repository'\n","  drive_mount_location = '/content/drive'\n","\n","  drive.mount(drive_mount_location, force_remount=True)\n","  path.append(root_PATH)\n","\n","  install_dependecies()\n","else:\n","  root_PATH = os.path.abspath(\"../..\")\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","module_path = os.path.abspath(os.path.join('../../src'))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 22.3MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 48.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 51.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=7806c5749973d1d665dd568db040a3f724f95494b632ac5583710d29530ed203\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oh2VBalDF5YF","executionInfo":{"status":"ok","timestamp":1609154652148,"user_tz":-60,"elapsed":13958,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["#imports\n","import pandas as pd\n","from torch import cuda\n","from transformers import BertTokenizer, BertModel, BertConfig\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import transformers\n","import numpy as np\n","from sklearn import metrics"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RVUukP1VF5YG"},"source":["## Configuration variables"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["4226a375a5834773bf922fb5a8097866","2b4ba0e511d0449eb16522f06105bbba","c8c58a7f977947578c9a1c74c7a4004a","a495d83fdba446ca9a1967a8d3f2120f","34006378d81941a79325e4b98614ab1c","f236e56b821e4820bf95917babe5bf26","5e6be3f61aa74ecebc6204eb5e6c79cc","65a06a01075c4c17bcb1a20a7b56d10a"]},"id":"damtmGHsF5YH","executionInfo":{"status":"ok","timestamp":1609154652398,"user_tz":-60,"elapsed":11930,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"918f33da-5d5f-4cf3-862c-7c0529347272"},"source":["# Defining some key variables that will be used later on in the training\n","MAX_LEN = 200\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","gpus_to_use = [0]"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4226a375a5834773bf922fb5a8097866","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yyBrXzucF5YI"},"source":["## Preprocess dataset"]},{"cell_type":"code","metadata":{"id":"RVOFNqZsF5YJ","executionInfo":{"status":"ok","timestamp":1609154655529,"user_tz":-60,"elapsed":11910,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["#Load datasets\n","train_df = pd.read_csv(root_PATH + '/data/train.csv')\n","validation_df = pd.read_csv(root_PATH + '/data/validation.csv')\n","\n","#train_df = train_df.head(100)\n","#validation_df = validation_df.head(100)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"6onGgfcZF5YJ","executionInfo":{"status":"ok","timestamp":1609154662230,"user_tz":-60,"elapsed":5899,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["#Obtain a list with all the topics in the dataset\n","train_df[\"Topic\"] = train_df[\"Topic\"].apply(eval)\n","validation_df[\"Topic\"] = validation_df[\"Topic\"].apply(eval)\n","\n","def list_to_series(series):\n","    return pd.Series([x for _list in series for x in _list])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNG4bA1bF5YJ","executionInfo":{"status":"ok","timestamp":1609154668419,"user_tz":-60,"elapsed":10484,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["#Add a boolean mask to the dataset\n","def boolean_df(item_lists, unique_items):# Create empty dict\n","    bool_dict = {}\n","    \n","    # Loop through all the tags\n","    for i, item in enumerate(unique_items):\n","        \n","        # Apply boolean mask\n","        bool_dict[item] = item_lists.apply(lambda x: item in x)\n","            \n","    # Return the results as a dataframe\n","    return pd.DataFrame(bool_dict)\n","\n","train_topics = list_to_series(train_df[\"Topic\"]).value_counts().index.tolist()\n","train_boolean_mask = boolean_df(train_df[\"Topic\"],train_topics).astype(int)\n","\n","validation_topics = list_to_series(validation_df[\"Topic\"]).value_counts().index.tolist()\n","validation_boolean_mask = boolean_df(validation_df[\"Topic\"],train_topics).astype(int)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqV3vfYPF5YJ","executionInfo":{"status":"ok","timestamp":1609154670992,"user_tz":-60,"elapsed":5639,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["train_df[\"list\"] = train_boolean_mask.values.tolist()\n","validation_df[\"list\"] = validation_boolean_mask.values.tolist()\n","\n","train_df = train_df[[\"Conversation\",\"list\"]]\n","validation_df = train_df[[\"Conversation\",\"list\"]]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vRoIRsaF5YK"},"source":["## Custom Dataloader"]},{"cell_type":"code","metadata":{"id":"zHl3BkPmF5YL","executionInfo":{"status":"ok","timestamp":1609154670994,"user_tz":-60,"elapsed":1431,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.comment_text = dataframe.Conversation\n","        self.targets = self.data.list\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.comment_text)\n","\n","    def __getitem__(self, index):\n","        \n","        comment_text = str(self.comment_text[index])\n","        #comment_text = \" \".join(comment_text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            comment_text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation = True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDbXXlWGF5YM","executionInfo":{"status":"ok","timestamp":1609154672786,"user_tz":-60,"elapsed":656,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["training_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n","testing_set = CustomDataset(validation_df, tokenizer, MAX_LEN)\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C36TkTo6F5YM"},"source":["## Neural Network Definition"]},{"cell_type":"code","metadata":{"id":"-qtem5OAF5YM","executionInfo":{"status":"ok","timestamp":1609154676416,"user_tz":-60,"elapsed":469,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}}},"source":["#TODO: set dropout and learning rate as hyperparameters\n","#TODO: drop topics with too few samples and adjust NN\n","class BERTClass(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n","        self.l2 = torch.nn.Dropout(0.3)\n","        self.l3 = torch.nn.Linear(768, 33)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n","        output_2 = self.l2(output_1)\n","        output = self.l3(output_2)\n","        return output"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"xXJp7Ln0F5YM","executionInfo":{"status":"error","timestamp":1609074122016,"user_tz":-60,"elapsed":1215,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"e146eb76-d944-49e0-bba9-f2abdc4a9140"},"source":["model = BERTClass()\n","model.to(device)\n","\n","def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n","\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0af5fdcd3e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'BERTClass' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"qfJeJLc2F5YN"},"source":["## Model Fine Tunning"]},{"cell_type":"code","metadata":{"id":"-nYduuf5F5YN"},"source":["def train(epoch):\n","\n","    model.train()\n","    \n","    for _,data in enumerate(training_loader, 0):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        outputs = model(ids, mask, token_type_ids)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","        \n","        if _%5000==0:\n","        #if _%32==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"Zxi2g6TIF5YN","executionInfo":{"status":"error","timestamp":1609057901984,"user_tz":-60,"elapsed":1337147,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"4577cbb9-f549-43ab-8e82-a8f186c8b7a5"},"source":["for epoch in range(EPOCHS):\n","    train(epoch)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0, Loss:  0.6774767637252808\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c6928e977afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-a8cfb55f6de5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"FMVCnqzZNk8H"},"source":["def validation(epoch):\r\n","    model.eval()\r\n","    fin_targets=[]\r\n","    fin_outputs=[]\r\n","    with torch.no_grad():\r\n","        for _, data in enumerate(testing_loader, 0):\r\n","            ids = data['ids'].to(device, dtype = torch.long)\r\n","            mask = data['mask'].to(device, dtype = torch.long)\r\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\r\n","            targets = data['targets'].to(device, dtype = torch.float)\r\n","            outputs = model(ids, mask, token_type_ids)\r\n","            fin_targets.extend(targets.cpu().detach().numpy().tolist())\r\n","            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\r\n","    return fin_outputs, fin_targets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"id":"tigcoBuuU05X","executionInfo":{"status":"error","timestamp":1609058038748,"user_tz":-60,"elapsed":107411,"user":{"displayName":"Pablo Restrepo","photoUrl":"","userId":"07173891156719463289"}},"outputId":"5c3bd82b-423b-4023-8483-6f29fac95e03"},"source":["for epoch in range(EPOCHS):\r\n","    outputs, targets = validation(epoch)\r\n","    outputs = np.array(outputs) >= 0.5\r\n","    accuracy = metrics.accuracy_score(targets, outputs)\r\n","    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\r\n","    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\r\n","    print(f\"Accuracy Score = {accuracy}\")\r\n","    print(f\"F1 Score (Micro) = {f1_score_micro}\")\r\n","    print(f\"F1 Score (Macro) = {f1_score_macro}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-aea8401fee88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf1_score_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-9972a8403887>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mfin_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mfin_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfin_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}