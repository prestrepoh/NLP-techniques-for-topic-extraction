{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('NLP-seminar-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a192f6a2a07440443dd9813f45d39f6276bab8996f4682d1023cc32088b348cc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount Drive and install dependencies if running in Colab\n",
    "def install_dependecies():\n",
    "  !pip install transformers\n",
    "  !pip install pytorch-lightning\n",
    "\n",
    "from sys import path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "\n",
    "  root_PATH = '/content/drive/My Drive/nlp-seminar/repository'\n",
    "  drive_mount_location = '/content/drive'\n",
    "  module_path = root_PATH + '/src'\n",
    "  \n",
    "  drive.mount(drive_mount_location, force_remount=True)\n",
    "  path.append(root_PATH)\n",
    "\n",
    "  install_dependecies()\n",
    "else:\n",
    "  root_PATH = os.path.abspath(\"../../..\")\n",
    "  module_path = os.path.abspath(os.path.join('../../../src'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import DataProcessor\n",
    "from model_evaluator import ModelEvaluator\n",
    "from custom_dataset import CustomDataset\n",
    "from models.BERT.my_bert_model import MyBERTModel\n",
    "\n",
    "import pandas as pd\n",
    "from torch import cuda\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script configuration\n",
    "MAX_LEN = 200\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "model_to_use = 'bert-base-uncased'\n",
    "model_path = root_PATH + '/models/deep_learning/BERT/tb_logs_corrected_epoc5_backup/my_BERT_model/version_0/checkpoints/epoch=4.ckpt'\n",
    "\n",
    "#Model parameters\n",
    "model_params = {\n",
    "                'test_batch_size': TEST_BATCH_SIZE\n",
    "                }\n",
    "\n",
    "gpus_to_use = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "test_df = pd.read_csv(root_PATH + '/data/test.csv')\n",
    "\n",
    "#Get boolean mask of the datasets\n",
    "test_boolean_mask = test_df.iloc[:,8:]\n",
    "\n",
    "#Get topics present in the dataset\n",
    "remaining_topics = test_boolean_mask.columns.tolist()\n",
    "\n",
    "#Create new column with the boolean mask\n",
    "test_df[\"list\"] = test_boolean_mask.values.tolist()\n",
    "\n",
    "#Remove columns not necessary from the datasets\n",
    "test_df = test_df[[\"conversation\",\"list\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "testing_set = CustomDataset(test_df, tokenizer, MAX_LEN)\n",
    "data_loader = DataLoader(testing_set, batch_size=TEST_BATCH_SIZE, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Testing: 100%|██████████| 60/60 [01:14<00:00,  1.22s/it]Total accuracy: 0.3828125\n",
      "Accuracy per label: {'Satisfied users': 0.6932291666666667, 'Bugs': 0.8890625, 'Design & UX': 0.8984375, 'Dissatisfied users': 0.9291666666666667, 'Performance': 0.9348958333333334, 'Use cases': 0.9505208333333334, 'Gaming': 0.9463541666666667, 'Feature Requests': 0.9572916666666667, 'Complexity': 0.965625, 'Pricing': 0.9614583333333333, 'Security & Accounts': 0.9692708333333333, 'Update': 0.9635416666666666, 'Camera & Photos': 0.96875, 'Video': 0.9598958333333333, 'Customer Support': 0.9651041666666667, 'Notifications & Alerts': 0.9697916666666667, 'Frequency': 0.9739583333333334, 'Advertising': 0.9770833333333333, 'Payment': 0.9817708333333334, 'Connectivity': 0.98125, 'Devices': 0.9838541666666667, 'Audio': 0.971875, 'Sign Up & Login': 0.9885416666666667, 'Location Services': 0.9890625, 'Privacy': 0.9864583333333333, 'Internationalization': 0.9885416666666667, 'no topic': 0.9178433889602053}\n",
      "Testing: 100%|██████████| 60/60 [01:14<00:00,  1.24s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model = MyBERTModel.load_from_checkpoint(\n",
    "    model_path, \n",
    "    hparams = model_params, \n",
    "    training_dataset=None, \n",
    "    validation_dataset=None, \n",
    "    labels=remaining_topics, \n",
    "    model_to_use=model_to_use\n",
    "    )\n",
    "\n",
    "trainer = pl.Trainer(gpus=gpus_to_use,\n",
    "                             #accelerator='dp',\n",
    "                             #limit_train_batches=32,\n",
    "                             #limit_val_batches=32,\n",
    "                             #limit_test_batches=60,\n",
    "                             #max_epochs=200,\n",
    "                             #logger=logger,\n",
    "                             #default_root_dir=logs_path\n",
    "                             )\n",
    "\n",
    "trainer.test(ckpt_path=model_path,model=model,test_dataloaders=[data_loader])"
   ]
  }
 ]
}