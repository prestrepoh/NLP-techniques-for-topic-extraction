{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('NLP-seminar-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a192f6a2a07440443dd9813f45d39f6276bab8996f4682d1023cc32088b348cc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount Drive and install dependencies if running in Colab\n",
    "def install_dependecies():\n",
    "  !pip install transformers\n",
    "  !pip install pytorch-lightning\n",
    "\n",
    "from sys import path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "\n",
    "  root_PATH = '/content/drive/My Drive/nlp-seminar/repository'\n",
    "  drive_mount_location = '/content/drive'\n",
    "  module_path = root_PATH + '/src'\n",
    "  \n",
    "  drive.mount(drive_mount_location, force_remount=True)\n",
    "  path.append(root_PATH)\n",
    "\n",
    "  install_dependecies()\n",
    "else:\n",
    "  root_PATH = os.path.abspath(\"../../..\")\n",
    "  module_path = os.path.abspath(os.path.join('../../../src'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import DataProcessor\n",
    "from model_evaluator import ModelEvaluator\n",
    "from models.BERT.bert_custom_dataset import BERTCustomDataset\n",
    "from models.BERT.my_bert_model import MyBERTModel\n",
    "\n",
    "import pandas as pd\n",
    "from torch import cuda\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script configuration\n",
    "MAX_LEN = 200\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "model_to_use = 'bert-base-cased'\n",
    "model_path = root_PATH + '/models/deep_learning/BERT/tb_logs_corrected_epoc5_backup/my_BERT_model/version_0/checkpoints/epoch=4.ckpt'\n",
    "\n",
    "#Model parameters\n",
    "model_params = {\n",
    "                'test_batch_size': TEST_BATCH_SIZE\n",
    "                }\n",
    "gpus_to_use = [0]\n",
    "\n",
    "#remove under-represented categories below this treshold\n",
    "underrepresented_threshold = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "train_df = pd.read_csv(root_PATH + '/data/train.csv')\n",
    "test_df = pd.read_csv(root_PATH + '/data/test.csv')\n",
    "\n",
    "#Convert topics column to list\n",
    "train_df[\"Topic\"] = train_df[\"Topic\"].apply(eval)\n",
    "test_df[\"Topic\"] = test_df[\"Topic\"].apply(eval)\n",
    "\n",
    "#Generate boolean masks for our datasets\n",
    "train_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(train_df)\n",
    "test_boolean_mask = DataProcessor.obtain_boolean_mask_from_dataset(test_df)\n",
    "\n",
    "#Remove underrepresented topics\n",
    "underrepresented_topics = DataProcessor.get_underrepresented_topics(train_df,underrepresented_threshold)\n",
    "\n",
    "train_df, remaining_topics = DataProcessor.remove_topics_from_dataset(train_df,train_boolean_mask,underrepresented_topics)\n",
    "test_df, _ = DataProcessor.remove_topics_from_dataset(test_df,test_boolean_mask,underrepresented_topics)\n",
    "\n",
    "#Get boolean masks of our new dataset\n",
    "test_boolean_mask = test_df.iloc[:,9:]\n",
    "\n",
    "#Select relevant columns for testing our model\n",
    "test_df[\"list\"] = test_boolean_mask.values.tolist()\n",
    "\n",
    "test_df = test_df[[\"Conversation\",\"list\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "testing_set = BERTCustomDataset(test_df, tokenizer, MAX_LEN)\n",
    "data_loader = DataLoader(testing_set, batch_size=TEST_BATCH_SIZE, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Testing: 100%|██████████| 60/60 [01:09<00:00,  1.23s/it]Total accuracy: 0.7890625\n",
      "Accuracy per label: {'Satisfied users': 0.9296875, 'Bugs': 0.9854166666666667, 'Design & UX': 0.9911458333333333, 'Dissatisfied users': 0.9760416666666667, 'Performance': 0.99375, 'Use cases': 0.996875, 'Gaming': 0.9979166666666667, 'Feature Requests': 0.99375, 'Complexity': 0.9958333333333333, 'Security & Accounts': 0.946875, 'Update': 0.9479166666666666, 'Pricing': 0.946875, 'Camera & Photos': 0.9473958333333333, 'Video': 0.9989583333333333, 'Customer Support': 0.9963541666666667, 'Notifications & Alerts': 1.0, 'Frequency': 0.9963541666666667, 'Advertising': 0.9994791666666667, 'Payment': 0.9989583333333333, 'Connectivity': 0.9979166666666667, 'Devices': 0.9984375, 'Audio': 0.9989583333333333, 'Sign Up & Login': 1.0, 'Location Services': 0.9994791666666667, 'Privacy': 0.9989583333333333, 'Internationalization': 1.0, 'no topic': 0.8729946524064172}\n",
      "Testing: 100%|██████████| 60/60 [01:09<00:00,  1.16s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model = MyBERTModel.load_from_checkpoint(model_path, hparams = model_params, training_dataset=None, validation_dataset=None, labels=remaining_topics, model_to_use='bert-base-uncased')\n",
    "\n",
    "trainer = pl.Trainer(gpus=gpus_to_use,\n",
    "                             #accelerator='dp',\n",
    "                             #limit_train_batches=32,\n",
    "                             #limit_val_batches=32,\n",
    "                             limit_test_batches=60,\n",
    "                             #max_epochs=200,\n",
    "                             #logger=logger,\n",
    "                             #default_root_dir=logs_path\n",
    "                             )\n",
    "\n",
    "trainer.test(ckpt_path=model_path,model=model,test_dataloaders=[data_loader])"
   ]
  }
 ]
}